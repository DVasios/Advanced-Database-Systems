{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8595e621",
   "metadata": {},
   "source": [
    "# Advanced Database Systems - NTUA - 2023\n",
    "\n",
    "\n",
    "## Project Scope\n",
    "\n",
    "## \n",
    "\n",
    "### Contributors\n",
    "\n",
    "Dimitris Vasios 03119404\n",
    "\n",
    "Thodoris - Angelos Mexis 03118408"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a63360",
   "metadata": {},
   "source": [
    "### Script to enable the cluster\n",
    "**Cluster Specification**\n",
    "\n",
    "Namenode\n",
    "\n",
    "Datanodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfbf5e6-14ae-4b72-a1a3-a646a1e3a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType, DateType, DoubleType, TimestampType, TimestampNTZType\n",
    "from pyspark.sql.functions import col, count, asc, desc\n",
    "from pyspark.sql.functions import year, month, count, dense_rank, row_number, to_date\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType, DateType\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Other Libraries\n",
    "import subprocess as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f317561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary data for the project\n",
    "sp.call(['bash', '../scripts/import_data.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe07f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Cluster\n",
    "sp.call(['bash', '../scripts/cluster_initiate.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Primary Data into one csv\n",
    "crime_data_2010_2019 = pd.read_csv('../data/primary/crime_data_2010_2019.csv')\n",
    "crime_data_2020_present = pd.read_csv('../data/primary/crime_data_2020_present.csv')\n",
    "crime_data = pd.concat([crime_data_2010_2019, crime_data_2020_present], ignore_index=True)\n",
    "crime_data.to_csv('../data/primary/crime_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a379c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data to HDFS\n",
    "sp.call(['bash', '../scripts/load_data_to_hdfs.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8667758a-80a5-4331-bf2a-d455d43a4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/06 18:17:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/06 18:17:55 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# Start a Spark Session\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Standard Query\") \\\n",
    "    .getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de184b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime Data Total Rows : 2993433\n",
      "Date Rptd: [('DR_NO', 'string'), ('Date Rptd', 'date'), ('DATE OCC', 'date'), ('TIME OCC', 'string'), ('AREA', 'string'), ('AREA NAME', 'string'), ('Rpt Dist No', 'string'), ('Part 1-2', 'string'), ('Crm Cd', 'string'), ('Crm Cd Desc', 'string'), ('Mocodes', 'string'), ('Vict Age', 'int'), ('Vict Sex', 'string'), ('Vict Descent', 'string'), ('Premis Cd', 'string'), ('Premis Desc', 'string'), ('Weapon Used Cd', 'string'), ('Weapon Desc', 'string'), ('Status', 'string'), ('Status Desc', 'string'), ('Crm Cd 1', 'string'), ('Crm Cd 2', 'string'), ('Crm Cd 3', 'string'), ('Crm Cd 4', 'string'), ('LOCATION', 'string'), ('Cross Street', 'string'), ('LAT', 'double'), ('LON', 'double')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Crime Data Schema\n",
    "crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", StringType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", StringType()),\n",
    "    StructField(\"AREA\", StringType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", StringType()),\n",
    "    StructField(\"Part 1-2\", StringType()),\n",
    "    StructField(\"Crm Cd\", StringType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", StringType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", StringType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", StringType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", StringType()),\n",
    "    StructField(\"Crm Cd 2\", StringType()),\n",
    "    StructField(\"Crm Cd 3\", StringType()),\n",
    "    StructField(\"Crm Cd 4\", StringType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", StringType()),\n",
    "    StructField(\"LON\", StringType()),\n",
    "])\n",
    "\n",
    "crime_data_df = sc.read.format('csv') \\\n",
    "    .options(header='true') \\\n",
    "    .schema(crime_data_schema) \\\n",
    "    .load(\"hdfs://okeanos-master:54310/user/data/primary/crime_data.csv\")\n",
    "\n",
    "# Change Columns types\n",
    "crime_data_df = crime_data_df.withColumn('Date Rptd', to_date('Date Rptd', 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "                             .withColumn('DATE OCC', to_date('DATE OCC', 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "                             .withColumn('Vict Age', col('Vict Age').cast('int')) \\\n",
    "                             .withColumn('LAT',col('LAT').cast('double')) \\\n",
    "                             .withColumn('LON', col('LON').cast('double'))\n",
    "\n",
    "crime_data_df.dtypes\n",
    "\n",
    "rows = crime_data_df.count()\n",
    "print(f\"Crime Data Total Rows : {rows}\")\n",
    "print(f\"Date Rptd: {crime_data_df.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aadbd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---+\n",
      "|Year|Month|crimetotal|  #|\n",
      "+----+-----+----------+---+\n",
      "|2010|    3|     17595|  1|\n",
      "|2010|    7|     17520|  2|\n",
      "|2010|    5|     17338|  3|\n",
      "|2011|    8|     17139|  1|\n",
      "|2011|    5|     17050|  2|\n",
      "|2011|    3|     16951|  3|\n",
      "|2012|    8|     17696|  1|\n",
      "|2012|   10|     17477|  2|\n",
      "|2012|    5|     17391|  3|\n",
      "|2013|    8|     17329|  1|\n",
      "|2013|    7|     16714|  2|\n",
      "|2013|    5|     16671|  3|\n",
      "|2014|    7|     14059|  1|\n",
      "|2014|   10|     14031|  2|\n",
      "|2014|    9|     13799|  3|\n",
      "|2015|    8|     18951|  1|\n",
      "|2015|   10|     18916|  2|\n",
      "|2015|    7|     18528|  3|\n",
      "|2016|    8|     19779|  1|\n",
      "|2016|   10|     19615|  2|\n",
      "|2016|    7|     19262|  3|\n",
      "|2017|   10|     20400|  1|\n",
      "|2017|    8|     20086|  2|\n",
      "|2017|    7|     19997|  3|\n",
      "|2018|    5|     20248|  1|\n",
      "|2018|    7|     19972|  2|\n",
      "|2018|   10|     19814|  3|\n",
      "|2019|    7|     19338|  1|\n",
      "|2019|    8|     19074|  2|\n",
      "|2019|    3|     18932|  3|\n",
      "|2020|    1|     18488|  1|\n",
      "|2020|    2|     17436|  2|\n",
      "|2020|    7|     17241|  3|\n",
      "|2021|   11|     23889|  1|\n",
      "|2021|   10|     23882|  2|\n",
      "|2021|   12|     23852|  3|\n",
      "|2022|    5|     21090|  1|\n",
      "|2022|    1|     20845|  2|\n",
      "|2022|    8|     20760|  3|\n",
      "|2023|    8|     20408|  1|\n",
      "|2023|   10|     20385|  2|\n",
      "|2023|    1|     20276|  3|\n",
      "+----+-----+----------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ---- QUERY 1 | DATAFRAME API-----\n",
    "\n",
    "# Keep specific columns from the dataframe\n",
    "crime_data_date = crime_data_df.select('Date Rptd')\n",
    "\n",
    "# Extract year and month from the 'date_occ' column\n",
    "crime_data_year_month = crime_data_date.withColumn('Year', year('Date Rptd')) \\\n",
    "                                       .withColumn('Month', month('Date Rptd'))\n",
    "\n",
    "# Calculate counts for each year and month\n",
    "counts = crime_data_year_month.groupBy('Year', 'Month').agg(count('*').alias('crimetotal'))\n",
    "\n",
    "# Order by Year and Total Crimes Crimes\n",
    "partitioned = Window.partitionBy('Year').orderBy(counts['crimetotal'].desc())\n",
    "\n",
    "# Add a rank column to the DataFrame\n",
    "ranked_df = counts.withColumn('rnk', dense_rank().over(partitioned))\n",
    "\n",
    "# Filter the top 3 counts for each year\n",
    "top3_df = ranked_df.filter('rnk <= 3')\n",
    "\n",
    "top3 = top3_df.withColumnRenamed('rnk', '#')\n",
    "\n",
    "# Show the results\n",
    "top3.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9dd12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Query 1\n",
    "# # query_1 = \"SELECT 'Date Rptd' as date_rptd from \"\n",
    "# crime_data_df.createOrReplaceTempView(\"crime_data\")\n",
    "# crime_data_query_1 = sc.sql(\"select * from crime_data limit 100\")\n",
    "# crime_data_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f90708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/primary/crime_data.csv', nrows=1000)\n",
    "# df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
