{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8595e621",
   "metadata": {},
   "source": [
    "# Advanced Database Systems - NTUA - 2023\n",
    "\n",
    "\n",
    "## Project Scope\n",
    "\n",
    "## \n",
    "\n",
    "### Contributors\n",
    "\n",
    "Dimitris Vasios 03119404\n",
    "\n",
    "Thodoris - Angelos Mexis 03118408"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a63360",
   "metadata": {},
   "source": [
    "### Script to enable the cluster\n",
    "**Cluster Specification**\n",
    "\n",
    "Namenode\n",
    "\n",
    "Datanodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfbf5e6-14ae-4b72-a1a3-a646a1e3a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyspark Libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, StringType\n",
    "from pyspark.sql.functions import col, count, when, to_timestamp\n",
    "from pyspark.sql.functions import year, month, count, dense_rank\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Other Libraries\n",
    "import subprocess as sp\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f317561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download necessary data for the project\n",
    "sp.call(['bash', '../scripts/import_data.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe07f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Cluster\n",
    "sp.call(['bash', '../scripts/cluster_initiate.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Primary Data into one csv\n",
    "crime_data_2010_2019 = pd.read_csv('../data/primary/crime_data_2010_2019.csv')\n",
    "crime_data_2020_present = pd.read_csv('../data/primary/crime_data_2020_present.csv')\n",
    "crime_data = pd.concat([crime_data_2010_2019, crime_data_2020_present], ignore_index=True)\n",
    "crime_data.to_csv('../data/primary/crime_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a379c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data to HDFS\n",
    "sp.call(['bash', '../scripts/load_data_to_hdfs.sh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8667758a-80a5-4331-bf2a-d455d43a4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/10 18:35:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/10 18:35:31 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# Start a Spark Session\n",
    "sc = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Standard Query\") \\\n",
    "    .getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de184b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime Data Total Rows : 696937\n",
      "Date Rptd: [('DR_NO', 'string'), ('Date Rptd', 'timestamp'), ('DATE OCC', 'timestamp'), ('TIME OCC', 'int'), ('AREA', 'string'), ('AREA NAME', 'string'), ('Rpt Dist No', 'string'), ('Part 1-2', 'string'), ('Crm Cd', 'string'), ('Crm Cd Desc', 'string'), ('Mocodes', 'string'), ('Vict Age', 'int'), ('Vict Sex', 'string'), ('Vict Descent', 'string'), ('Premis Cd', 'string'), ('Premis Desc', 'string'), ('Weapon Used Cd', 'string'), ('Weapon Desc', 'string'), ('Status', 'string'), ('Status Desc', 'string'), ('Crm Cd 1', 'string'), ('Crm Cd 2', 'string'), ('Crm Cd 3', 'string'), ('Crm Cd 4', 'string'), ('LOCATION', 'string'), ('Cross Street', 'string'), ('LAT', 'double'), ('LON', 'double')]\n"
     ]
    }
   ],
   "source": [
    "# Crime Data Schema\n",
    "crime_data_schema = StructType([\n",
    "    StructField(\"DR_NO\", StringType()),\n",
    "    StructField(\"Date Rptd\", StringType()),\n",
    "    StructField(\"DATE OCC\", StringType()),\n",
    "    StructField(\"TIME OCC\", StringType()),\n",
    "    StructField(\"AREA\", StringType()),\n",
    "    StructField(\"AREA NAME\", StringType()),\n",
    "    StructField(\"Rpt Dist No\", StringType()),\n",
    "    StructField(\"Part 1-2\", StringType()),\n",
    "    StructField(\"Crm Cd\", StringType()),\n",
    "    StructField(\"Crm Cd Desc\", StringType()),\n",
    "    StructField(\"Mocodes\", StringType()),\n",
    "    StructField(\"Vict Age\", StringType()),\n",
    "    StructField(\"Vict Sex\", StringType()),\n",
    "    StructField(\"Vict Descent\", StringType()),\n",
    "    StructField(\"Premis Cd\", StringType()),\n",
    "    StructField(\"Premis Desc\", StringType()),\n",
    "    StructField(\"Weapon Used Cd\", StringType()),\n",
    "    StructField(\"Weapon Desc\", StringType()),\n",
    "    StructField(\"Status\", StringType()),\n",
    "    StructField(\"Status Desc\", StringType()),\n",
    "    StructField(\"Crm Cd 1\", StringType()),\n",
    "    StructField(\"Crm Cd 2\", StringType()),\n",
    "    StructField(\"Crm Cd 3\", StringType()),\n",
    "    StructField(\"Crm Cd 4\", StringType()),\n",
    "    StructField(\"LOCATION\", StringType()),\n",
    "    StructField(\"Cross Street\", StringType()),\n",
    "    StructField(\"LAT\", StringType()),\n",
    "    StructField(\"LON\", StringType()),\n",
    "])\n",
    "\n",
    "crime_data_df = sc.read.format('csv') \\\n",
    "    .options(header='true') \\\n",
    "    .schema(crime_data_schema) \\\n",
    "    .load(\"hdfs://okeanos-master:54310/user/data/primary/crime_data.csv\")\n",
    "\n",
    "# Change Columns types\n",
    "crime_data_df = crime_data_df.withColumn('Date Rptd', to_timestamp('Date Rptd', 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "                             .withColumn('DATE OCC', to_timestamp('DATE OCC', 'MM/dd/yyyy hh:mm:ss a')) \\\n",
    "                             .withColumn('TIME OCC', col('TIME OCC').cast('int')) \\\n",
    "                             .withColumn('Vict Age', col('Vict Age').cast('int')) \\\n",
    "                             .withColumn('LAT',col('LAT').cast('double')) \\\n",
    "                             .withColumn('LON', col('LON').cast('double'))\n",
    "\n",
    "\n",
    "rows = crime_data_df.filter(crime_data_df['Premis Desc'] == 'STREET').count()\n",
    "print(f\"Crime Data Total Rows : {rows}\")\n",
    "print(f\"Date Rptd: {crime_data_df.dtypes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aadbd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---+\n",
      "|Year|Month|crimetotal|  #|\n",
      "+----+-----+----------+---+\n",
      "|2010|    3|     17595|  1|\n",
      "|2010|    7|     17520|  2|\n",
      "|2010|    5|     17338|  3|\n",
      "|2011|    8|     17139|  1|\n",
      "|2011|    5|     17050|  2|\n",
      "|2011|    3|     16951|  3|\n",
      "|2012|    8|     17696|  1|\n",
      "|2012|   10|     17477|  2|\n",
      "|2012|    5|     17391|  3|\n",
      "|2013|    8|     17329|  1|\n",
      "|2013|    7|     16714|  2|\n",
      "|2013|    5|     16671|  3|\n",
      "|2014|    7|     14059|  1|\n",
      "|2014|   10|     14031|  2|\n",
      "|2014|    9|     13799|  3|\n",
      "|2015|    8|     18951|  1|\n",
      "|2015|   10|     18916|  2|\n",
      "|2015|    7|     18528|  3|\n",
      "|2016|    8|     19779|  1|\n",
      "|2016|   10|     19615|  2|\n",
      "|2016|    7|     19262|  3|\n",
      "|2017|   10|     20400|  1|\n",
      "|2017|    8|     20086|  2|\n",
      "|2017|    7|     19997|  3|\n",
      "|2018|    5|     20248|  1|\n",
      "|2018|    7|     19972|  2|\n",
      "|2018|   10|     19814|  3|\n",
      "|2019|    7|     19338|  1|\n",
      "|2019|    8|     19074|  2|\n",
      "|2019|    3|     18932|  3|\n",
      "|2020|    1|     18488|  1|\n",
      "|2020|    2|     17436|  2|\n",
      "|2020|    7|     17241|  3|\n",
      "|2021|   11|     23889|  1|\n",
      "|2021|   10|     23882|  2|\n",
      "|2021|   12|     23852|  3|\n",
      "|2022|    5|     21090|  1|\n",
      "|2022|    1|     20845|  2|\n",
      "|2022|    8|     20760|  3|\n",
      "|2023|    8|     20408|  1|\n",
      "|2023|   10|     20385|  2|\n",
      "|2023|    1|     20276|  3|\n",
      "+----+-----+----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- QUERY 1 | DATAFRAME API-----\n",
    "\n",
    "# Keep specific columns from the dataframe\n",
    "crime_data_date = crime_data_df.select('Date Rptd')\n",
    "\n",
    "# Extract year and month from the 'date_occ' column\n",
    "crime_data_year_month = crime_data_date.withColumn('Year', year('Date Rptd')) \\\n",
    "                                       .withColumn('Month', month('Date Rptd'))\n",
    "\n",
    "# Calculate counts for each year and month\n",
    "counts = crime_data_year_month.groupBy('Year', 'Month').agg(count('*').alias('crimetotal'))\n",
    "\n",
    "# Order by Year and Total Crimes Crimes\n",
    "partitioned = Window.partitionBy('Year').orderBy(counts['crimetotal'].desc())\n",
    "\n",
    "# Add a rank column to the DataFrame\n",
    "ranked_df = counts.withColumn('rnk', dense_rank().over(partitioned))\n",
    "\n",
    "# Filter the top 3 counts for each year\n",
    "top3_df = ranked_df.filter('rnk <= 3')\n",
    "\n",
    "# Rename the rank column\n",
    "top3 = top3_df.withColumnRenamed('rnk', '#')\n",
    "\n",
    "# Show the results\n",
    "top3.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9dd12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/01/10 18:37:32 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 9:=================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----------+----------+\n",
      "|Year|Month|crime_count|month_rank|\n",
      "+----+-----+-----------+----------+\n",
      "|2010|    3|      17595|         1|\n",
      "|2010|    7|      17520|         2|\n",
      "|2010|    5|      17338|         3|\n",
      "|2011|    8|      17139|         1|\n",
      "|2011|    5|      17050|         2|\n",
      "|2011|    3|      16951|         3|\n",
      "|2012|    8|      17696|         1|\n",
      "|2012|   10|      17477|         2|\n",
      "|2012|    5|      17391|         3|\n",
      "|2013|    8|      17329|         1|\n",
      "|2013|    7|      16714|         2|\n",
      "|2013|    5|      16671|         3|\n",
      "|2014|    7|      14059|         1|\n",
      "|2014|   10|      14031|         2|\n",
      "|2014|    9|      13799|         3|\n",
      "|2015|    8|      18951|         1|\n",
      "|2015|   10|      18916|         2|\n",
      "|2015|    7|      18528|         3|\n",
      "|2016|    8|      19779|         1|\n",
      "|2016|   10|      19615|         2|\n",
      "+----+-----+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----- Query 1 | SQL API\n",
    "query_1_sql = \"\"\" with MonthlyCrimeCounts AS ( \n",
    "  SELECT  \n",
    "    EXTRACT(YEAR FROM `Date Rptd`) AS Year, \n",
    "    EXTRACT(MONTH FROM `Date Rptd`) AS Month, \n",
    "    COUNT(*) AS crime_count,  \n",
    "    ROW_NUMBER() OVER (PARTITION BY EXTRACT(YEAR FROM `Date Rptd`) ORDER BY COUNT(*) DESC) AS rn \n",
    "  FROM \n",
    "    crime_data\n",
    "  GROUP BY \n",
    "    Year, \n",
    "    Month \n",
    ") \n",
    "\n",
    "SELECT \n",
    "  Year, \n",
    "  Month, \n",
    "  crime_count, \n",
    "  rn AS month_rank  \n",
    "FROM \n",
    "  MonthlyCrimeCounts \n",
    "WHERE \n",
    "  rn <= 3 \n",
    "ORDER BY \n",
    "  Year ASC, \n",
    "  crime_count DESC; \"\"\"\n",
    "\n",
    "crime_data_df.createOrReplaceTempView(\"crime_data\")\n",
    "crime_data_query_1 = sc.sql(query_1_sql)\n",
    "crime_data_query_1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99b615fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark For Query 1\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4ee8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|PartOfDay|NumberOfCrimes|\n",
      "+---------+--------------+\n",
      "|    Night|        237605|\n",
      "|Afternoon|        187306|\n",
      "|     Noon|        148180|\n",
      "|  Morning|        123846|\n",
      "+---------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----- Query 2 | Dataframe API\n",
    "\n",
    "query_2 = crime_data_df \\\n",
    "    .filter(crime_data_df['Premis Desc'] == 'STREET') \\\n",
    "    .withColumn( \n",
    "        'PartOfDay', \n",
    "        when((crime_data_df['TIME OCC'] >= 500) & (crime_data_df['TIME OCC'] < 1200), 'Morning') \\\n",
    "        .when((crime_data_df['TIME OCC'] >= 1200) & (crime_data_df['TIME OCC'] < 1700), 'Noon') \\\n",
    "        .when((crime_data_df['TIME OCC'] >= 1700) & (crime_data_df['TIME OCC'] < 2100), 'Afternoon') \\\n",
    "        .when((crime_data_df['TIME OCC'] >= 2100) & (crime_data_df['TIME OCC'] < 2400) |\n",
    "              (crime_data_df['TIME OCC'] >= 0) & (crime_data_df['TIME OCC'] < 500), 'Night') \\\n",
    "        .otherwise('NoPartOfDay')) \\\n",
    "    .select(col('TIME OCC').alias('time'), col('PartOfDay')) \\\n",
    "    .groupBy(col('PartOfDay')).agg(count('*').alias('NumberOfCrimes')) \\\n",
    "    .orderBy(col('NumberOfCrimes').desc()) \n",
    "\n",
    "# Print Output\n",
    "query_2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17ada9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|PartOfDay|NumberOfCrimes|\n",
      "+---------+--------------+\n",
      "|    Night|        237605|\n",
      "|Afternoon|        187306|\n",
      "|     Noon|        148180|\n",
      "|  Morning|        123846|\n",
      "+---------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ----- Query 2 | SQL API\n",
    "\n",
    "crime_data_df.createOrReplaceTempView(\"crime_data\")\n",
    "\n",
    "query_2_sql = \"\"\"\n",
    "\n",
    "WITH OnlyInStreet AS (\n",
    "  SELECT \n",
    "    `TIME OCC` as time,\n",
    "    CASE \n",
    "      WHEN time >= 500 AND time < 1200 THEN 'Morning'\n",
    "      WHEN time >= 1200 AND time < 1700 THEN 'Noon' \n",
    "      WHEN time >= 1700 AND time < 2100 THEN 'Afternoon' \n",
    "      WHEN time >= 2100 AND time < 2400 OR time >=0 AND time < 500 THEN 'Night' \n",
    "    END AS PartOfDay\n",
    "  FROM\n",
    "    crime_data\n",
    "  WHERE\n",
    "    `Premis Desc`='STREET'\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  PartOfDay,\n",
    "  COUNT(PartOFDay) as NumberOfCrimes\n",
    "FROM\n",
    "  OnlyInStreet\n",
    "GROUP BY\n",
    "  PartOfDay\n",
    "ORDER BY\n",
    "  NumberOfCrimes DESC;\n",
    "\"\"\"\n",
    "\n",
    "crime_data_query = sc.sql(query_2_sql).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f999189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/01/10 15:59:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/01/10 15:59:35 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "# ----- Query 2 | RDD API\n",
    "\n",
    "# sc = SparkSession \\\n",
    "#      .builder \\\n",
    "#      .appName(\"RDD API | Query 2\") \\\n",
    "#      .getOrCreate() \\\n",
    "#      .sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35fc0525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RDD Dataframe\n",
    "rdd_from_df = crime_data_df.rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56552bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Afternoon', 187306), ('Noon', 148180), ('Night', 237605)]\n"
     ]
    }
   ],
   "source": [
    "def categorize(x): \n",
    "    if x[0] >= 500 and x[0] < 1200:\n",
    "        return ('Morning', 1)\n",
    "    elif x[0] >= 1200 and x[0] < 1700:\n",
    "        return ('Noon', 1)\n",
    "    elif x[0] >= 1700 and x[0] < 2100:\n",
    "        return ('Afternoon', 1)\n",
    "    elif (x[0] >= 2100 and x[0] < 2400) or (x[0] >= 0 and x[0] < 500):\n",
    "        return ('Night', 1)\n",
    "        \n",
    "# rdd = sc.textFile(\"hdfs://okeanos-master:54310/user/data/primary/crime_data.csv\") \n",
    "# rdd = sc.textFile(\"../data/primary/crime_data.csv\") \n",
    "\n",
    "data_rdd = rdd_from_df \\\n",
    "                .map(lambda x: (int(x[3]), str(x[15]))) \\\n",
    "                .filter(lambda x: x[1] == \"STREET\") \\\n",
    "                .map(categorize) \\\n",
    "                .reduceByKey(lambda x, y: x+y) \n",
    "\n",
    "print(data_rdd.take(3))\n",
    "# print(data_rdd.map(lambda x: [x[15]]).take(10))\n",
    "# print(data_rdd.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a926ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Query 3 | Dataframe API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Query 3 | SQL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f30fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Query 4 | Dataframe API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Query 4 | SQL API"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
